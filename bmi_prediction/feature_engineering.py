# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.decomposition import PCA
from sklearn.ensemble import (
    RandomForestRegressor, GradientBoostingRegressor
)
from sklearn.linear_model import Ridge, LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

# XGBoost, LightGBM, CatBoost ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor

# TensorFlow ë° Keras ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# ì „ì—­ ë³€ìˆ˜ íŒŒì¼ import
from model_training import train_and_evaluate, models  # ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ import
import model_training as mt

import global_variables as gv

# ëœë¤ ì‹œë“œ ê³ ì •
np.random.seed(42)
tf.random.set_seed(42)

# -----------------------------
# ë°ì´í„° ì „ì²˜ë¦¬: PCA ë³€í™˜ ì ìš©
# -----------------------------
def apply_pca(n_components=5):
    """
    PCA ë³€í™˜ì„ ìˆ˜í–‰í•˜ê³  gvì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    if gv.X_train_scaled is None or gv.X_test_scaled is None:
        raise ValueError("âŒ X_train_scaled ë˜ëŠ” X_test_scaledê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")

    pca = PCA(n_components=n_components)
    gv.X_train_pca = pca.fit_transform(gv.X_train_scaled)
    gv.X_test_pca = pca.transform(gv.X_test_scaled)
    
    # âœ… PCA ë¶„ì‚° ì„¤ëª…ë¥  ì €ì¥
    gv.explained_variance_ratio = pca.explained_variance_ratio_

    print("âœ… PCA ë³€í™˜ ì™„ë£Œ.")

# -----------------------------
# ì‹ ê²½ë§ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
# -----------------------------
def build_nn():
    model = Sequential([
        Dense(64, activation='relu', input_shape=(gv.X_train_pca.shape[1],)),
        Dense(64, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

# -----------------------------
# íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” í•¨ìˆ˜ ì •ì˜
# -----------------------------
def plot_feature_importance(model, model_name):
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        plt.figure(figsize=(10, 6))
        plt.barh(range(len(importances)), importances, color='skyblue')
        plt.xlabel('ì¤‘ìš”ë„')
        plt.title(f'{model_name} íŠ¹ì„± ì¤‘ìš”ë„')
        plt.gca().invert_yaxis()
        plt.show()
    else:
        print(f"{model_name}ì€ feature_importances_ ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------
# ì‹¤í–‰ ì½”ë“œ (if __name__ == "__main__")
# -----------------------------
if __name__ == "__main__":
    print("ğŸš€ PCA ì ìš© ì¤‘...")
    apply_pca()  # âœ… PCA ë¨¼ì € ì‹¤í–‰

    # ì „ì—­ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    X_train_pca = gv.X_train_pca
    X_test_pca = gv.X_test_pca
    y_train = gv.y_train
    y_test = gv.y_test

    print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    for name, model in models.items():
        train_and_evaluate(model, X_train_pca, y_train, X_test_pca, y_test, name)

    # ì‹ ê²½ë§ ëª¨ë¸ í•™ìŠµ
    print("ğŸš€ ì‹ ê²½ë§ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    nn_model = build_nn()
    nn_model.fit(X_train_pca, y_train, validation_data=(X_test_pca, y_test), epochs=50, batch_size=32, verbose=0)
    
    # ì˜ˆì¸¡ ë° í‰ê°€
    y_pred_nn = nn_model.predict(X_test_pca).ravel()
    print(f"< PCA ì ìš© ì‹ ê²½ë§ ëª¨ë¸ >")
    print(f"MSE : {mean_squared_error(y_test, y_pred_nn):.3f}")
    print(f"RMSE : {np.sqrt(mean_squared_error(y_test, y_pred_nn)):.3f}")
    print(f"ê²°ì •ê³„ìˆ˜ : {r2_score(y_test, y_pred_nn):.3f}\n")

    # íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
    for name, model in models.items():
        plot_feature_importance(model, name)

    print("âœ… Feature Engineering ì™„ë£Œ!")