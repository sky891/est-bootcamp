from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import os

# âœ… ëœë¤ ì‹œë“œ ê³ ì •
np.random.seed(42)
tf.random.set_seed(42)

def train_t_lstm_time_interval():
    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    DATA_PATH = os.path.join(BASE_DIR, "data", "data_resampled.csv")
    
    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DATA_PATH}\nğŸ“Œ `preprocessing.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv(DATA_PATH)
    print(f"âœ… ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {DATA_PATH}")
    print(df.info())
    
    # ì‹œê°„ ë³€í™˜ ë° ì •ë ¬
    df = pd.read_csv(DATA_PATH, index_col=0)  # 'time'ì´ ì¸ë±ìŠ¤ë¡œ ë˜ì–´ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
    df.reset_index(inplace=True)
    
    # ì‹œê°„ ê°„ê²© ê³„ì‚°
    df['time_interval'] = df['time'].diff().dt.total_seconds().fillna(0)
    df.set_index('time', inplace=True)
    
    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    columns_to_scale = ['latitude', 'longitude', 'depth', 'rms', 'time_interval']
    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])
    
    X = df.drop('time_interval', axis=1)
    y = df['mag']
    time_interval = df['time_interval']
    timesteps = 30
    
    # ë°ì´í„° ë¶„í• 
    train_size = int(len(df) * 0.8)
    val_size = int(len(df) * 0.1)
    
    def create_sequences(X, y, timesteps):
        X_seq, y_seq, time_interval_seq = [], [], []
        for i in range(len(X) - timesteps):
            X_seq.append(X.iloc[i:i+timesteps].values)
            y_seq.append(y.iloc[i+timesteps])
            time_interval_seq.append(time_interval.iloc[i:i+timesteps].values)
        return np.array(X_seq), np.array(y_seq), np.array(time_interval_seq).reshape(-1, timesteps, 1)
    
    X_train, y_train, time_interval_train = create_sequences(X[:train_size], y[:train_size], timesteps)
    X_val, y_val, time_interval_val = create_sequences(X[train_size:train_size + val_size], y[train_size:train_size + val_size], timesteps)
    X_test, y_test, time_interval_test = create_sequences(X[train_size + val_size:], y[train_size + val_size:], timesteps)
    
    # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    epoch = 10
    batch_size = 32
    learning_rate = 0.001
    
    # ì…ë ¥ ë ˆì´ì–´
    X_input = Input(shape=(X_train.shape[1], X_train.shape[2]), name='X_input')
    time_input = Input(shape=(X_train.shape[1], 1), name='time_input')
    merged_input = Concatenate()([X_input, time_input])
    
    # LSTM ëª¨ë¸
    lstm_out_1 = LSTM(128, return_sequences=True)(merged_input)
    lstm_out_2 = LSTM(64, return_sequences=False)(lstm_out_1)
    output = Dense(1, activation='linear', name='output')(lstm_out_2)
    
    model = Model(inputs=[X_input, time_input], outputs=output)
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=['mae'])
    
    history = model.fit(
        [X_train, time_interval_train], y_train,
        validation_df=([X_val, time_interval_val], y_val),
        epochs=epoch, batch_size=batch_size,
        verbose=1
    )
    
    # ëª¨ë¸ í‰ê°€
    y_pred = model.predict([X_test, time_interval_test])
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    print(f"Test MSE: {mse}, Test MAE: {mae}, Test R2 Score: {r2}")
    
    # ì†ì‹¤ ê·¸ë˜í”„
    plt.figure(figsize=(12, 5))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('MSE Loss')
    plt.title(f'Training and Validation Loss')
    plt.legend()
    plt.show()
    
    # ì˜ˆì¸¡ê°’ ê·¸ë˜í”„
    plt.figure(figsize=(12, 5))
    plt.plot(y_test, label='Actual')
    plt.plot(y_pred, label='Predicted')
    plt.xlabel('Samples')
    plt.ylabel('Magnitude')
    plt.title(f'Actual vs Predicted Magnitude')
    plt.legend()
    plt.show()
    
    return model